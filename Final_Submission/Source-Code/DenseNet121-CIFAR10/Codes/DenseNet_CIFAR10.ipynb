{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Download packages"
      ],
      "metadata": {
        "id": "uOKXZ6ngXT4n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/qubvel/classification_models.git"
      ],
      "metadata": {
        "id": "I6YcQt85y9MF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d60360d-00ff-49d4-ab22-cbcc82470e06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/qubvel/classification_models.git\n",
            "  Cloning https://github.com/qubvel/classification_models.git to /tmp/pip-req-build-1cnxoa22\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/qubvel/classification_models.git /tmp/pip-req-build-1cnxoa22\n",
            "  Resolved https://github.com/qubvel/classification_models.git to commit a0f006e05485a34ccf871c421279864b0ccd220b\n",
            "  Running command git submodule update --init --recursive -q\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras_applications<=1.0.8,>=1.0.7\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.9/dist-packages (from keras_applications<=1.0.8,>=1.0.7->image-classifiers==1.0.0) (3.8.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.9/dist-packages (from keras_applications<=1.0.8,>=1.0.7->image-classifiers==1.0.0) (1.22.4)\n",
            "Building wheels for collected packages: image-classifiers\n",
            "  Building wheel for image-classifiers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for image-classifiers: filename=image_classifiers-1.0.0-py3-none-any.whl size=20048 sha256=c3bab6b166bebf291bc0246d92bcbd45221912d4ca2b8122aa1828c033e88fab\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-zpscph9b/wheels/e7/c3/c8/78c1f9edf72d00198ac018396707125272de9c1abdd99a4043\n",
            "Successfully built image-classifiers\n",
            "Installing collected packages: keras_applications, image-classifiers\n",
            "Successfully installed image-classifiers-1.0.0 keras_applications-1.0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-addons"
      ],
      "metadata": {
        "id": "Rb9vhsV3y9Yv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5135dd8a-00f6-4f7c-a173-3fcd648379d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.20.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (591 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m591.0/591.0 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typeguard<3.0.0,>=2.7\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from tensorflow-addons) (23.1)\n",
            "Installing collected packages: typeguard, tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.20.0 typeguard-2.13.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialisation and data cleaning"
      ],
      "metadata": {
        "id": "2sK_zYFDYcDj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IzPMGElT94Zi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cf2d42f-e4eb-4206-f0cc-a7a153a2e997"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Import lib\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, Add, Flatten, Dense, GlobalAveragePooling2D, MaxPooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.applications.densenet import DenseNet121\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.optimizers import Adam, SGD, Nadam\n",
        "import time\n",
        "from classification_models.keras import Classifiers\n",
        "import tensorflow_addons as tfa\n",
        "from keras import backend as K"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "print(subprocess.getoutput('nvidia-smi'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umI8BnLP98nL",
        "outputId": "7cc7a746-503a-41c3-9d67-5b9ad43f28ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Apr 23 23:03:31 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  NVIDIA A100-SXM...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P0    48W / 400W |      0MiB / 40960MiB |      0%      Default |\n",
            "|                               |                      |             Disabled |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Convert class vectors to binary class matrices\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "def preprocess_image(image, label):\n",
        "    image = tf.image.resize(image, (224, 224))\n",
        "    image = tf.keras.applications.vgg16.preprocess_input(image)\n",
        "    return image, label\n",
        "\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "train_ds = train_ds.map(preprocess_image).batch(32)\n",
        "\n",
        "val_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
        "val_ds = val_ds.map(preprocess_image).batch(32)"
      ],
      "metadata": {
        "id": "jykrldBx-MWW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e50a2ea-bb77-4bf3-b5f3-5855c4e548db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 13s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build VGGNet-16 and padam"
      ],
      "metadata": {
        "id": "dv0fNujvYgMh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 10\n",
        "base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "x = Flatten()(base_model.output)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "output = Dense(num_classes, activation='softmax')(x)\n",
        "model = Model(inputs=base_model.input, outputs=output)"
      ],
      "metadata": {
        "id": "GGrPtdqM-PyE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d839191e-63c4-4dad-c04d-b17b828a267f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "29084464/29084464 [==============================] - 2s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Padam(tfa.optimizers.RectifiedAdam):\n",
        "    def __init__(self, p=0.5, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.p = p\n",
        "        \n",
        "    def _resource_apply_dense(self, grad, var, apply_state=None):\n",
        "        var_dtype = var.dtype.base_dtype\n",
        "        local_step = tf.cast(self.iterations + 1, var_dtype)\n",
        "        beta_1_t = tf.cast(self._get_hyper('beta_1', var_dtype), var_dtype)\n",
        "        beta_2_t = tf.cast(self._get_hyper('beta_2', var_dtype), var_dtype)\n",
        "        one_minus_beta_1_t = 1 - beta_1_t\n",
        "        one_minus_beta_2_t = 1 - beta_2_t\n",
        "        \n",
        "        step_size = self._get_hyper('learning_rate', var_dtype) * (tf.sqrt(1 - tf.pow(beta_2_t, local_step)) / (1 - tf.pow(beta_1_t, local_step)))\n",
        "\n",
        "        m = self.get_slot(var, 'm')\n",
        "        m_t = (m * beta_1_t) + (grad * one_minus_beta_1_t)\n",
        "        m_hat_t = m_t / (1 - tf.pow(beta_1_t, local_step))\n",
        "        \n",
        "        v = self.get_slot(var, 'v')\n",
        "        v_t = (v * beta_2_t) + (tf.square(grad) * one_minus_beta_2_t)\n",
        "        v_hat_t = v_t / (1 - tf.pow(beta_2_t, local_step))\n",
        "        \n",
        "        denom = tf.pow(tf.sqrt(v_hat_t) + K.epsilon(), self.p)\n",
        "        var_t = var - step_size * (m_hat_t / denom)\n",
        "        \n",
        "        return tf.compat.v1.assign(var, var_t)"
      ],
      "metadata": {
        "id": "0FLwcC40zDT1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model_with_optimizer(optimizer, batch_size, epochs):\n",
        "    # Untested merge start #\n",
        "    num_classes = 10\n",
        "    base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "    x = Flatten()(base_model.output)\n",
        "    x = Dense(1024, activation='relu')(x)\n",
        "    x = Dense(512, activation='relu')(x)\n",
        "    output = Dense(num_classes, activation='softmax')(x)\n",
        "    model = Model(inputs=base_model.input, outputs=output)\n",
        "    # Untested merge finished #\n",
        "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy', 'top_k_categorical_accuracy'])\n",
        "    start_time = time.time()\n",
        "    history = model.fit(train_ds, batch_size=batch_size, epochs=epochs, validation_data=val_ds, verbose=0)\n",
        "    end_time = time.time()\n",
        "    training_time = end_time - start_time\n",
        "    return history, training_time, model"
      ],
      "metadata": {
        "id": "HVA9mAIs-emD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Model"
      ],
      "metadata": {
        "id": "uTa297O-YkI2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 200 epochs (Same as the paper)\n",
        "# Need to re-complie the model if ran 50 epochs before\n",
        "optimizers = {\n",
        "    'Adam': Adam(learning_rate=0.001),\n",
        "    'SGD': SGD(learning_rate=0.001, momentum=0.9),\n",
        "    'Nadam': Nadam(learning_rate=0.001),\n",
        "    'Adam_Amsgrad': Adam(learning_rate=0.001, amsgrad=True),\n",
        "    'Padam': Padam(learning_rate=0.1, total_steps=10000, p=0.125, beta_1=0.9, beta_2=0.999, weight_decay=5e-4)\n",
        "}\n",
        "\n",
        "histories = {}\n",
        "training_times = {}\n",
        "models = {}\n",
        "\n",
        "for name, optimizer in optimizers.items():\n",
        "    print(f\"Training with {name} optimizer...\")\n",
        "    histories[name], training_times[name], models[name] = train_model_with_optimizer(optimizer, 32, 100)\n",
        "\n",
        "for name, model in models.items():\n",
        "    model.save(f'./Model/resnet_model_{name}.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "D9Lo7GwG-gpa",
        "outputId": "251fa9a1-6622-432d-cdbe-311f03105e96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training with Adam optimizer...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-a59978e60061>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Training with {name} optimizer...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mhistories\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_times\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model_with_optimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-8c96080b05f0>\u001b[0m in \u001b[0;36mtrain_model_with_optimizer\u001b[0;34m(optimizer, batch_size, epochs)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'top_k_categorical_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mtraining_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mend_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1674\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1675\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1676\u001b[0;31m                     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1677\u001b[0m                         with tf.profiler.experimental.Trace(\n\u001b[1;32m   1678\u001b[0m                             \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36msteps\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1373\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Set by `catch_stop_iteration`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1374\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1375\u001b[0;31m             \u001b[0moriginal_spe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps_per_execution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1376\u001b[0m             can_run_full_execution = (\n\u001b[1;32m   1377\u001b[0m                 \u001b[0moriginal_spe\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    645\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 647\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    648\u001b[0m     raise NotImplementedError(\n\u001b[1;32m    649\u001b[0m         \"numpy() is only available when eager execution is enabled.\")\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1158\u001b[0m     \"\"\"\n\u001b[1;32m   1159\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1160\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1161\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1124\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1125\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1126\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1127\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plot figure without padam"
      ],
      "metadata": {
        "id": "b1TwlvtXYpk8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "for name, history in histories.items():\n",
        "  if name != 'Padam':\n",
        "    plt.plot(history.history['loss'], label=f\"{name}\")\n",
        "\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.title('Training Loss Comparison for Different Optimizers')\n",
        "# Save the figure before displaying it\n",
        "plt.savefig('./Results/Train_Loss_nopadam.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VF8YzQg8zLAq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "for name, history in histories.items():\n",
        "  if name != 'Padam':\n",
        "    test_error = [1 - accuracy for accuracy in history.history['val_accuracy']]\n",
        "    plt.plot(test_error, label=f\"{name}\", linestyle='--')\n",
        "\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss / Error')\n",
        "plt.legend()\n",
        "plt.title('Test Error Comparison for Different Optimizers')\n",
        "# Save the figure before displaying it\n",
        "plt.savefig('./Results/Test_Error_nopadam.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "j5uSMZzczMG0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "for name, history in histories.items():\n",
        "  if name != 'Padam':\n",
        "    plt.plot(history.history['val_accuracy'], label=f\"{name}\")\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.title('Validation Accuracy for Different Optimizers')\n",
        "plt.savefig('./Results/validation_accuracy_nopadam.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xHO-1NLfzMP2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "# Exclude the 'Padam' optimizer\n",
        "filtered_optimizers = {k: v for k, v in training_times.items() if k != 'Padam'}\n",
        "\n",
        "plt.bar(filtered_optimizers.keys(), filtered_optimizers.values())\n",
        "plt.xlabel('Optimizer')\n",
        "plt.ylabel('Time (s)')\n",
        "plt.title('Training Time for Different Optimizers (excluding Padam)')\n",
        "\n",
        "plt.savefig('./Results/training_time_nopadam.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MGt_AGdhzMaZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "# Training Loss\n",
        "for name, history in histories.items():\n",
        "  if name != 'Padam':\n",
        "    axes[0, 0].plot(history.history['loss'], label=f\"{name}\")\n",
        "axes[0, 0].set_xlabel('Epochs')\n",
        "axes[0, 0].set_ylabel('Loss')\n",
        "axes[0, 0].legend()\n",
        "axes[0, 0].set_title('Training Loss')\n",
        "\n",
        "# Test Error\n",
        "for name, history in histories.items():\n",
        "  if name != 'Padam':\n",
        "    test_error = [1 - accuracy for accuracy in history.history['val_accuracy']]\n",
        "    axes[0, 1].plot(test_error, label=f\"{name}\")\n",
        "axes[0, 1].set_xlabel('Epochs')\n",
        "axes[0, 1].set_ylabel('Error')\n",
        "axes[0, 1].legend()\n",
        "axes[0, 1].set_title('Test Error')\n",
        "\n",
        "# Validation Accuracy\n",
        "for name, history in histories.items():\n",
        "  if name != 'Padam':\n",
        "    axes[1, 0].plot(history.history['val_accuracy'], label=f\"{name}\")\n",
        "axes[1, 0].set_xlabel('Epochs')\n",
        "axes[1, 0].set_ylabel('Accuracy')\n",
        "axes[1, 0].legend()\n",
        "axes[1, 0].set_title('Validation Accuracy')\n",
        "\n",
        "# Training Time\n",
        "filtered_optimizers = {k: v for k, v in training_times.items() if k != 'Padam'}\n",
        "axes[1, 1].bar(filtered_optimizers.keys(), filtered_optimizers.values())\n",
        "axes[1, 1].set_xlabel('Optimizer')\n",
        "axes[1, 1].set_ylabel('Time (s)')\n",
        "axes[1, 1].set_title('Training Time')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('./Results/matrix_nopadam.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dNshDBO2zMnY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plot figure with padam"
      ],
      "metadata": {
        "id": "de7FiInwYsBY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "for name, history in histories.items():\n",
        "    plt.plot(history.history['loss'], label=f\"{name}\")\n",
        "\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.title('Training Loss Comparison for Different Optimizers')\n",
        "# Save the figure before displaying it\n",
        "plt.savefig('./Results/Train_Loss.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zF6-GvfAzM6G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "for name, history in histories.items():\n",
        "    # plt.plot(history.history['loss'], label=f\"{name} Training Loss\")\n",
        "    test_error = [1 - accuracy for accuracy in history.history['val_accuracy']]\n",
        "    plt.plot(test_error, label=f\"{name}\", linestyle='--')\n",
        "\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss / Error')\n",
        "plt.legend()\n",
        "plt.title('Test Error Comparison for Different Optimizers')\n",
        "# Save the figure before displaying it\n",
        "plt.savefig('./Results/Test_Error.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lWqc34kfzNDA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "for name, history in histories.items():\n",
        "    plt.plot(history.history['val_accuracy'], label=f\"{name}\")\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.title('Validation Accuracy for Different Optimizers')\n",
        "plt.savefig('./Results/validation_accuracy.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1bH6kqJ6zNOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "plt.bar(training_times.keys(), training_times.values())\n",
        "plt.xlabel('Optimizer')\n",
        "plt.ylabel('Time (s)')\n",
        "plt.title('Training Time for Different Optimizers')\n",
        "plt.savefig('./Results/training_time.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Ncy_cjoVzNhb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "# Training Loss\n",
        "for name, history in histories.items():\n",
        "    axes[0, 0].plot(history.history['loss'], label=f\"{name}\")\n",
        "axes[0, 0].set_xlabel('Epochs')\n",
        "axes[0, 0].set_ylabel('Loss')\n",
        "axes[0, 0].legend()\n",
        "axes[0, 0].set_title('Training Loss')\n",
        "\n",
        "# Test Error\n",
        "for name, history in histories.items():\n",
        "    test_error = [1 - accuracy for accuracy in history.history['val_accuracy']]\n",
        "    axes[0, 1].plot(test_error, label=f\"{name}\")\n",
        "axes[0, 1].set_xlabel('Epochs')\n",
        "axes[0, 1].set_ylabel('Error')\n",
        "axes[0, 1].legend()\n",
        "axes[0, 1].set_title('Test Error')\n",
        "\n",
        "# Validation Accuracy\n",
        "for name, history in histories.items():\n",
        "    axes[1, 0].plot(history.history['val_accuracy'], label=f\"{name}\")\n",
        "axes[1, 0].set_xlabel('Epochs')\n",
        "axes[1, 0].set_ylabel('Accuracy')\n",
        "axes[1, 0].legend()\n",
        "axes[1, 0].set_title('Validation Accuracy')\n",
        "\n",
        "# Training Time\n",
        "axes[1, 1].bar(training_times.keys(), training_times.values())\n",
        "axes[1, 1].set_xlabel('Optimizer')\n",
        "axes[1, 1].set_ylabel('Time (s)')\n",
        "axes[1, 1].set_title('Training Time')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('./Results/matrix.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yiVLGtDRzNrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r Model.zip ./Model\n",
        "!zip -r Result.zip ./Results\n",
        "!cp Model.zip /content/drive/MyDrive/DenseNet/\n",
        "!cp Result.zip /content/drive/MyDrive/DenseNet/"
      ],
      "metadata": {
        "id": "iydi49sz4Fy6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}